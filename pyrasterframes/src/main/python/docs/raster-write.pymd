# Writing Raster Data

RasterFrames is oriented toward large scale analyses of spatial data. The primary output for most use cases may be a @ref:[statistical summary](aggregation.md), a @ref:[machine learning model](spark-ml.md), or some other result that is generally much smaller than the input data set. 

However there are times in any analysis where writing a representative sample of the work in progress provides invaluable feedback on the process and results.

```python imports, echo=False
import pyrasterframes
from pyrasterframes.rasterfunctions import *
from IPython.display import display
spark = pyrasterframes.get_spark_session()
```

## Tile Samples

When collecting a _tile_ (see discussion of the RasterFrame @ref:[schema](raster-read.md#single-raster) for orientation to the concept) to the Python Spark driver, we have some convenience methods to quickly visualize the _tile_. 

In an IPython or Jupyter interpreter a `Tile` object will be displayed as an image with limited metadata.

```python tile_sample
raster_url = 'https://modis-pds.s3.amazonaws.com/MCD43A4.006/11/08/2019059/' \
             'MCD43A4.A2019059.h11v08.006.2019072203257_B02.TIF'
spark_df = spark.read.raster(raster_url)
tile = spark_df.select(rf_tile('proj_raster').alias('tile')).first()['tile']
tile
```

```python display_tile, echo=False, output=True
display(tile) # IPython.display function
```

## DataFrame Samples

Within an IPython or Jupyter interpreter a Pandas DataFrame containing a column of _tiles_ will be rendered as the samples discussed above. Simply import the `rf_ipython` submodule to enable enhanced HTML rendering of a Pandas DataFrame.

In the example below, notice the result is limited to a small subset. For more discussion about why this is important, see the @ref:[Pandas and NumPy discussion](numpy-pandas.md).

```python toPandas, evaluate=True
import pyrasterframes.rf_ipython

pandas_df = spark.read.raster(raster_url, tile_dimensions=(64, 64)) \
                .select(
                    rf_extent('proj_raster').alias('extent'),
                    rf_tile('proj_raster').alias('tile'),
                ).limit(5).toPandas()
pandas_df.dtypes
```

Viewing the DataFrame in Jupyter looks like this. 

```python, evaluate=False
pandas_df
```

@@include[df-samples-output.md](static/df-samples-output.md)

## PNG Overviews

It is oftentimes convenient to have a simple overview image of the data, particularly if it spans a very wide area.

## GeoTIFFs

GeoTIFF is one of the most common file formats for spatial data. 

\[ See issue https://s22s.myjetbrains.com/youtrack/issue/RF-71 \]

## GeoTrellis Layers

[GeoTrellis][GeoTrellis] is one of the key libraries that RasterFrames builds upon. It provides a Scala language API to working with large raster data with Apache Spark. Ingesting raster data into a Layer is one of the key concepts for creating a dataset for processing on Spark. RasterFrames write data from an appropriate DataFrame into a GeoTrellis Layer.

\[ More details see https://s22s.myjetbrains.com/youtrack/issue/RF-72 \]


## Parquet

You can write the Spark DataFrame to an [Apache Parquet][Parquet] "file". This format is designed to work across different projects in the Hadoop ecosystem. It also provides a variety of optimizations for query against data written in the format. 

```python, evaluate=False
spark_df.withColumn('exp', rf_expm1('proj_raster')) \
    .write.mode('append').parquet('hdfs:///rf-user/sample.pq')
```

[GeoTrellis]: https://geotrellis.readthedocs.io/en/latest/
[Parquet]: https://spark.apache.org/docs/latest/sql-data-sources-parquet.html