{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests tqdm geopandas rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local dev env cruft\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/sfitch/Coding/earthai/src/main/python/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://donglebookpro.s22s.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10de0ba50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from earthai import *\n",
    "from pyrasterframes.rasterfunctions import *\n",
    "import geomesa_pyspark.types\n",
    "from earthai import earth_ondemand\n",
    "\n",
    "import pyrasterframes\n",
    "# spark = pyrasterframes.get_spark_session()\n",
    "from pyspark.sql.functions import lit, rand, when, col, array\n",
    "from pyspark.sql import SparkSession\n",
    "from pyrasterframes import utils\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "            .master('local[*]') \\\n",
    "            .config('spark.driver.memory', '12g') \\\n",
    "            .config('spark.jars', pyrasterframes.utils.find_pyrasterframes_assembly()) \\\n",
    "            .config('spark.serializer',\t'org.apache.spark.serializer.KryoSerializer') \\\n",
    "            .config('spark.kryoserializer.buffer.max', '2047m') \\\n",
    "            .getOrCreate() \n",
    "spark.withRasterFrames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LandSat Crop Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Landsat8 from EOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 16.33it/s]\n"
     ]
    }
   ],
   "source": [
    "eod = earth_ondemand.read_catalog(\n",
    "    geo=[-97.1, 47.4, -97.08, 47.5],\n",
    "    max_cloud_cover=10,\n",
    "    collections='landsat8_l1tp',\n",
    "    start_datetime='2018-07-01T00:00:00',\n",
    "    end_datetime='2018-08-31T23:59:59'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_df = eod[eod.eod_grid_id == \"WRS2-030027\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://landsat-pds.s3.us-west-2.amazonaws.com/c1/L8/030/027/LC08_L1TP_030027_20180717_20180730_01_T1/LC08_L1TP_030027_20180717_20180730_01_T1_B4.TIF'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(scene_df))\n",
    "teh_scene = scene_df.iloc[0].B4\n",
    "teh_scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Munge crop target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "\n",
    "aws s3 cp s3://s22s-sanda/sar-crop/target/scene_30_27_target.tif /tmp\n",
    "\n",
    "gdalinfo /vsicurl/https://landsat-pds.s3.us-west-2.amazonaws.com/c1/L8/030/027/LC08_L1TP_030027_20180717_20180730_01_T1/LC08_L1TP_030027_20180717_20180730_01_T1_B4.TIF\n",
    "\n",
    "gdalwarp -t_srs \"+proj=utm +zone=14 +datum=WGS84 +units=m +no_defs \" \\\n",
    "    -te  528885.000 5138685.000 760815.000 5373915.000 \\\n",
    "    -te_srs \"+proj=utm +zone=14 +datum=WGS84 +units=m +no_defs \" \\\n",
    "    -tr 30.0 30.0 \\\n",
    "    -co TILED=YES -co COPY_SRC_OVERVIEWS=YES -co COMPRESS=DEFLATE \\\n",
    "    scene_30_27_target.tif scene_30_27_target_utm.tif\n",
    " \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Read Raster Catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/jupyter-env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eod_collection_display_name</th>\n",
       "      <th>eod_collection_family</th>\n",
       "      <th>eod_collection_family_display_name</th>\n",
       "      <th>eod_grid_id</th>\n",
       "      <th>created</th>\n",
       "      <th>datetime</th>\n",
       "      <th>eo_cloud_cover</th>\n",
       "      <th>eo_constellation</th>\n",
       "      <th>eo_epsg</th>\n",
       "      <th>eo_gsd</th>\n",
       "      <th>...</th>\n",
       "      <th>B2</th>\n",
       "      <th>BQA</th>\n",
       "      <th>B4</th>\n",
       "      <th>B1</th>\n",
       "      <th>B8</th>\n",
       "      <th>B11</th>\n",
       "      <th>collection</th>\n",
       "      <th>geometry</th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Landsat 8</td>\n",
       "      <td>landsat8</td>\n",
       "      <td>Landsat 8</td>\n",
       "      <td>WRS2-030027</td>\n",
       "      <td>2019-08-19T20:54:33.413548Z</td>\n",
       "      <td>2018-07-17T17:15:57.1536740Z</td>\n",
       "      <td>1.49</td>\n",
       "      <td>landsat-8</td>\n",
       "      <td>32614</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>https://landsat-pds.s3.us-west-2.amazonaws.com...</td>\n",
       "      <td>https://landsat-pds.s3.us-west-2.amazonaws.com...</td>\n",
       "      <td>https://landsat-pds.s3.us-west-2.amazonaws.com...</td>\n",
       "      <td>https://landsat-pds.s3.us-west-2.amazonaws.com...</td>\n",
       "      <td>https://landsat-pds.s3.us-west-2.amazonaws.com...</td>\n",
       "      <td>https://landsat-pds.s3.us-west-2.amazonaws.com...</td>\n",
       "      <td>landsat8_l1tp</td>\n",
       "      <td>(POLYGON ((-98.62404379679178 46.4012557977134...</td>\n",
       "      <td>LC08_L1TP_030027_20180717_20180730_01_T1_L1TP</td>\n",
       "      <td>file:///tmp/scene_30_27_target_utm.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  eod_collection_display_name eod_collection_family  \\\n",
       "0                   Landsat 8              landsat8   \n",
       "\n",
       "  eod_collection_family_display_name  eod_grid_id  \\\n",
       "0                          Landsat 8  WRS2-030027   \n",
       "\n",
       "                       created                      datetime  eo_cloud_cover  \\\n",
       "0  2019-08-19T20:54:33.413548Z  2018-07-17T17:15:57.1536740Z            1.49   \n",
       "\n",
       "  eo_constellation  eo_epsg  eo_gsd  ...  \\\n",
       "0        landsat-8    32614    30.0  ...   \n",
       "\n",
       "                                                  B2  \\\n",
       "0  https://landsat-pds.s3.us-west-2.amazonaws.com...   \n",
       "\n",
       "                                                 BQA  \\\n",
       "0  https://landsat-pds.s3.us-west-2.amazonaws.com...   \n",
       "\n",
       "                                                  B4  \\\n",
       "0  https://landsat-pds.s3.us-west-2.amazonaws.com...   \n",
       "\n",
       "                                                  B1  \\\n",
       "0  https://landsat-pds.s3.us-west-2.amazonaws.com...   \n",
       "\n",
       "                                                  B8  \\\n",
       "0  https://landsat-pds.s3.us-west-2.amazonaws.com...   \n",
       "\n",
       "                                                 B11     collection  \\\n",
       "0  https://landsat-pds.s3.us-west-2.amazonaws.com...  landsat8_l1tp   \n",
       "\n",
       "                                            geometry  \\\n",
       "0  (POLYGON ((-98.62404379679178 46.4012557977134...   \n",
       "\n",
       "                                              id  \\\n",
       "0  LC08_L1TP_030027_20180717_20180730_01_T1_L1TP   \n",
       "\n",
       "                                   target  \n",
       "0  file:///tmp/scene_30_27_target_utm.tif  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_df['target'] = 'file:///tmp/scene_30_27_target_utm.tif'\n",
    "scene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rf = spark.read.raster(    \n",
    "    catalog=scene_df,\n",
    "    catalog_col_names=['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'BQA', 'target'],\n",
    "    tile_dimensions=(256, 256)\n",
    ").repartition(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rf = features_rf.withColumn('ndvi', rf_normalized_difference(features_rf.B5, features_rf.B4)) \\\n",
    "       .withColumn('ndwi1', rf_normalized_difference(features_rf.B5, features_rf.B6)) \\\n",
    "       .withColumn('ndwi2', rf_normalized_difference(features_rf.B5, features_rf.B7)) \\\n",
    "       .withColumn('ndwi3', rf_normalized_difference(features_rf.B3, features_rf.B5)) \\\n",
    "       .withColumn('evi', rf_local_multiply(rf_local_divide(rf_local_subtract(features_rf.B5, features_rf.B4), rf_local_add(rf_local_subtract(rf_local_add(features_rf.B5, rf_local_multiply(features_rf.B4, lit(6.0))), rf_local_multiply(features_rf.B2, lit(7.5))), lit(1.0))), lit(2.5))) \\\n",
    "       .withColumn('savi', rf_local_multiply(rf_local_divide(rf_local_subtract(features_rf.B5, features_rf.B4), rf_local_add(rf_local_add(features_rf.B5, features_rf.B4), lit(0.5))), lit(1.5))) \\\n",
    "       .withColumn('osavi', rf_local_divide(rf_local_subtract(features_rf.B5, features_rf.B4), rf_local_add(rf_local_add(features_rf.B5, features_rf.B4), lit(0.16)))) \\\n",
    "       .withColumn('satvi', rf_local_subtract(rf_local_multiply(rf_local_divide(rf_local_subtract(features_rf.B6, features_rf.B4),rf_local_add(rf_local_add(features_rf.B6, features_rf.B4), lit(0.5))), lit(1.5)), rf_local_divide(features_rf.B7, lit(2.0)))) \\\n",
    "       .withColumn('mean_swir', rf_local_divide(rf_local_add(features_rf.B6, features_rf.B7), lit(2.0))) \\\n",
    "       .withColumn('vli', rf_local_divide(rf_local_add(rf_local_add(rf_local_add(features_rf.B1, features_rf.B2), features_rf.B3), features_rf.B4), lit(4.0))) \\\n",
    "       .withColumn('dbsi', rf_local_subtract(rf_normalized_difference(features_rf.B6, features_rf.B3), rf_normalized_difference(features_rf.B5, features_rf.B4)))\n",
    "\n",
    "features_rf = features_rf.select(\n",
    "    features_rf.target,\n",
    "    rf_crs(features_rf.B1).alias('crs'),\n",
    "    rf_extent(features_rf.B1).alias('extent'),\n",
    "    rf_tile(features_rf.B1).alias('coastal'),\n",
    "    rf_tile(features_rf.B2).alias('blue'),\n",
    "    rf_tile(features_rf.B3).alias('green'),\n",
    "    rf_tile(features_rf.B4).alias('red'),\n",
    "    rf_tile(features_rf.B5).alias('nir'),\n",
    "    rf_tile(features_rf.B6).alias('swir1'),\n",
    "    rf_tile(features_rf.B7).alias('swir2'),\n",
    "    rf_tile(features_rf.ndvi).alias('ndvi'),\n",
    "    rf_tile(features_rf.ndwi1).alias('ndwi1'),\n",
    "    rf_tile(features_rf.ndwi2).alias('ndwi2'),\n",
    "    rf_tile(features_rf.ndwi3).alias('ndwi3'),\n",
    "    rf_tile(features_rf.evi).alias('evi'),\n",
    "    rf_tile(features_rf.savi).alias('savi'),\n",
    "    rf_tile(features_rf.osavi).alias('osavi'),\n",
    "    rf_tile(features_rf.satvi).alias('satvi'),\n",
    "    rf_tile(features_rf.mean_swir).alias('mean_swir'),\n",
    "    rf_tile(features_rf.vli).alias('vli'),\n",
    "    rf_tile(features_rf.dbsi).alias('dbsi'),\n",
    "    rf_tile(features_rf.BQA).alias('qa')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- target: struct (nullable = true)\n",
      " |    |-- tile_context: struct (nullable = false)\n",
      " |    |    |-- extent: struct (nullable = false)\n",
      " |    |    |    |-- xmin: double (nullable = false)\n",
      " |    |    |    |-- ymin: double (nullable = false)\n",
      " |    |    |    |-- xmax: double (nullable = false)\n",
      " |    |    |    |-- ymax: double (nullable = false)\n",
      " |    |    |-- crs: struct (nullable = false)\n",
      " |    |    |    |-- crsProj4: string (nullable = false)\n",
      " |    |-- tile: tile (nullable = false)\n",
      " |-- crs: struct (nullable = true)\n",
      " |    |-- crsProj4: string (nullable = false)\n",
      " |-- extent: struct (nullable = true)\n",
      " |    |-- xmin: double (nullable = false)\n",
      " |    |-- ymin: double (nullable = false)\n",
      " |    |-- xmax: double (nullable = false)\n",
      " |    |-- ymax: double (nullable = false)\n",
      " |-- coastal: tile (nullable = true)\n",
      " |-- blue: tile (nullable = true)\n",
      " |-- green: tile (nullable = true)\n",
      " |-- red: tile (nullable = true)\n",
      " |-- nir: tile (nullable = true)\n",
      " |-- swir1: tile (nullable = true)\n",
      " |-- swir2: tile (nullable = true)\n",
      " |-- ndvi: tile (nullable = true)\n",
      " |-- ndwi1: tile (nullable = true)\n",
      " |-- ndwi2: tile (nullable = true)\n",
      " |-- ndwi3: tile (nullable = true)\n",
      " |-- evi: tile (nullable = true)\n",
      " |-- savi: tile (nullable = true)\n",
      " |-- osavi: tile (nullable = true)\n",
      " |-- satvi: tile (nullable = true)\n",
      " |-- mean_swir: tile (nullable = true)\n",
      " |-- vli: tile (nullable = true)\n",
      " |-- dbsi: tile (nullable = true)\n",
      " |-- mask: tile (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Values of qa band indicating cloudy conditions\n",
    "cloud = [2800, 2804, 2808, 2812, 6896, 6900, 6904, 6908]\n",
    "\n",
    "mask_part = features_rf \\\n",
    "    .withColumn('cloud1', rf_local_equal('qa', lit(2800))) \\\n",
    "    .withColumn('cloud2', rf_local_equal('qa', lit(2804))) \\\n",
    "    .withColumn('cloud3', rf_local_equal('qa', lit(2808))) \\\n",
    "    .withColumn('cloud4', rf_local_equal('qa', lit(2812))) \\\n",
    "    .withColumn('cloud5', rf_local_equal('qa', lit(6896))) \\\n",
    "    .withColumn('cloud6', rf_local_equal('qa', lit(6900))) \\\n",
    "    .withColumn('cloud7', rf_local_equal('qa', lit(6904))) \\\n",
    "    .withColumn('cloud8', rf_local_equal('qa', lit(6908))) \n",
    "\n",
    "df_mask_inv = mask_part \\\n",
    "    .withColumn('mask', rf_local_add('cloud1', 'cloud2')) \\\n",
    "    .withColumn('mask', rf_local_add('mask', 'cloud3')) \\\n",
    "    .withColumn('mask', rf_local_add('mask', 'cloud4')) \\\n",
    "    .withColumn('mask', rf_local_add('mask', 'cloud5')) \\\n",
    "    .withColumn('mask', rf_local_add('mask', 'cloud6')) \\\n",
    "    .withColumn('mask', rf_local_add('mask', 'cloud7')) \\\n",
    "    .withColumn('mask', rf_local_add('mask', 'cloud8')) \\\n",
    "    .drop('cloud1', 'cloud2', 'cloud3', 'cloud4', 'cloud5', 'cloud6', 'cloud7', 'cloud8', 'qa')\n",
    "    \n",
    "# at this point the mask contains 0 for good cells and 1 for defect, etc\n",
    "# convert cell type and set value 1 to NoData\n",
    "# also set the value of 100 to nodata in the target. #darkarts\n",
    "mask_rf = df_mask_inv.withColumn('mask', rf_with_no_data(rf_convert_cell_type('mask', 'uint8'), 1.0)) \\\n",
    "                     .withColumn('target', rf_with_no_data('target', 100))\n",
    "\n",
    "mask_rf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = mask_rf.withColumn('train_set', when(rand(seed=1234) > 0.3, 1).otherwise(0))\n",
    "train_df = rf.filter(rf.train_set == 1)\n",
    "test_df = rf.filter(rf.train_set == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploded_df = train_df.select(rf_explode_tiles(array('coastal','blue','green','red','nir','swir1','swir2','ndvi','ndwi1','ndwi2','ndwi3','evi','savi','osavi','satvi','mean_swir','vli','dbsi','target', 'mask')))\n",
    "# exploded_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrasterframes import TileExploder\n",
    "from pyrasterframes.rf_types import NoDataFilter\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploder = TileExploder()\n",
    "\n",
    "noDataFilter = NoDataFilter() \\\n",
    "  .setInputCols(['target', 'mask'])\n",
    "\n",
    "assembler = VectorAssembler() \\\n",
    "  .setInputCols(['coastal','blue','green','red','nir','swir1','swir2','ndvi','ndwi1','ndwi2','ndwi3','evi','savi','osavi','satvi','mean_swir','vli','dbsi']) \\\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "classifier = DecisionTreeClassifier() \\\n",
    "  .setLabelCol('target') \\\n",
    "  .setMaxDepth(10) \\\n",
    "  .setFeaturesCol(assembler.getOutputCol())\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "  .setStages([exploder, noDataFilter, assembler, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.transform(train_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = model.transform(test_df) \\\n",
    "                       .drop(assembler.getOutputCol()).cache()\n",
    "prediction_df.printSchema()\n",
    "\n",
    "eval = MulticlassClassificationEvaluator(\n",
    "    predictionCol=classifier.getPredictionCol(),\n",
    "    labelCol=classifier.getLabelCol(),\n",
    "    metricName='fMeasureByThreshold'\n",
    ")\n",
    "\n",
    "f1score = eval.evaluate(prediction_df)\n",
    "print(\"\\nF1 Score:\", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_mtrx = prediction_df.groupBy(classifier.getPredictionCol()) \\\n",
    "    .pivot(classifier.getLabelCol()) \\\n",
    "    .count() \\\n",
    "    .sort(classifier.getPredictionCol())\n",
    "cnf_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
